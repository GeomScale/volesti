{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metabolic network analysis using *volestipy*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aim of this notebook is to present the complete pipeline for random sampling in a metabolic network using the ```volesitpy``` library. As input, we will use a BIGG model of human erythrocyte metabolism ([iAB-RBC-283](http://bigg.ucsd.edu/models/iAB_RBC_283)) in its ```.json``` format. \n",
    "\n",
    "This model consists of 342 metabolites and 469 reactions. \n",
    "\n",
    "Other formats, such as ```.mat``` are supported by ```volestipy``` but this is not in the scope of this tutorial. \n",
    "\n",
    "**Attention!**\n",
    "This tutorial assumes that you have already compiled the ```volestipy``` library, following the steps described [here](https://github.com/hariszaf/volume_approximation_bio/tree/develop/volestipy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With respect to this ```jupyter notebook```.\n",
    "First you need to create a **conda environment** by making use of at least Python 3.6. \n",
    "Then open the notebook using the ```jupyter notebook``` command after entering the conda evironment you built. \n",
    "\n",
    "For example, considering that the base environment of ```conda``` includes Python 3.6:\n",
    "\n",
    "```conda activate```\n",
    "\n",
    "```jupyter notebook```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use Jupyter with a certain conda environment we also need to run the followings:\n",
    "\n",
    "````conda install ipykernel\n",
    "ipython kernel install --name MY_CONDA_ENV --user\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before showing how you can exploit the *volestipy* software, we first need to get all the relative dependencies. \n",
    "\n",
    "This demo uses [Anaconda](https://www.anaconda.com/products/individual) which you can download following [these](https://www.digitalocean.com/community/tutorials/how-to-install-anaconda-on-ubuntu-18-04-quickstart) instructions.\n",
    "\n",
    "Furtheremore, special, powerful mathematical optimization solvers like [Gurobi](https://www.gurobi.com/) are also used. You can get Gurobi following the steps described [here](https://support.gurobi.com/hc/en-us/articles/360044290292-Installing-Gurobi-for-Python). Keep in mind that you will need a Gurobi license. To do this, you need to create a Gurobi user account and then follow the instructions for a license you will find there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main libraries you need to run this pipeline are the following:\n",
    "\n",
    "* ```numpy```\n",
    "* ```gurobipy``` and of course\n",
    "* ```volestipy```\n",
    "\n",
    "You will also need a library for plotting, like ```matplotib``` but this is up to you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get any libraries that need to run commands as ```sudo``` you need to make a file including **only** your password and replace ```/home/haris/Desktop/running/metabolic_network_pipeline_volestipy/my_project_virtual_env/error.txt``` with the corresponding path. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make possible to install what is needed in this conda evironment we use the ```getpass``` library that prompts the user for a password without echoing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import getpass \n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, with respect to the ```numpy``` library, let us first get it in our conda environment. \n",
    "This is going to take a while. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install --yes --prefix {sys.prefix} numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can import it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming you have already ```gurobipy``` on your computer, you may just add its path on your conda environment with the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/usr/local/lib/python3.6/dist-packages/gurobipy/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otherwise, you can install ```gurobipy``` on the conda enviroment directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get GUROBI through anaconda - You can find more about installing Gurobi here: \n",
    "# https://support.gurobi.com/hc/en-us/articles/360044290292-Installing-Gurobi-for-Python\n",
    "!conda install -y -c gurobi gurobi\n",
    "print(\"*** The Gurobi solver library has now been installed *** \\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After executing one of the above ways to get `gurobipy`, import this library and check if everything is working fine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "#from gurobipy import GRB\n",
    "\n",
    "# This is just a test that the Gurobi solver is well installed\n",
    "\n",
    "# Create a new model\n",
    "m = gp.Model(\"mip1\")\n",
    "\n",
    "print(\"\\n*** Gurobi test has been completed successfully. ***\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, for the `scipy` library. Install it through conda on this environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install --yes --prefix {sys.prefix} scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not need to import `scipy` here, however the `volestipy` does that. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have to compile and then import the ```volestipy``` library. To this end, we first need to get the `cython` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then run the following command as it was from our terminal. It is the `!` that allows for the latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!LDFLAGS=\"-L/usr/lib/lp_solve/\" python3 setup.py install --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from volestipy import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to read our network BIGG file and run the necessary steps to get our random points from its correspoding polytope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read your network file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have downloaded our BIGG model in its ```.json``` format. We keep this file as a variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = '/home/haris/bigg_files/iAB_RBC_283.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we run the ```volestipy``` function to read it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_erythrocyte_met_net = read_json_file(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may see the whole BIGG file, simply by printing the ```human_erythrocyte_met_net``` variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_erythrocyte_met_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the ```human_erythrocyte_met_net``` variable is a tuple, we can get its different features in a straight forward way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = human_erythrocyte_met_net[0]\n",
    "b = human_erythrocyte_met_net[1]\n",
    "Aeq = human_erythrocyte_met_net[2]\n",
    "beq = human_erythrocyte_met_net[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the ```Aeq``` variable is the stoichiometric matrix of the metabolic network under study, while in the ```beq``` variable we have its steady state. The variables ```A``` and ```b``` allow us to represent the upper and the lower bounds of the reactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look on these variables. ```Aeq``` our stoichiometric matrix has dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Aeq.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "meaning we have 342 metabolites that take part in 469 reactions. So, our network is built from these 95 reactions and their corresponding fluxes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let us also keep the reactions of the network in a variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactions = human_erythrocyte_met_net[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us assume that we are interested in one of the reactions that we saw before in the glycosylis path; the one that uses Hexokinase(HEX1) and is responsible for the following reaction:\n",
    "atp_c + glc__D_c ⇌ adp_c + g6p_c + h_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to find its index on the reactions list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactions.index('HEX1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then keep it as a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hexokinase = reactions[218]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can proceed in the necessary pre-processing steps for getting the polytope that derives from this metabolic network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of making things faster, we run a pre process step in order to run our pipeline in a more efficient, from a computational point of view, way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = pre_process(A, b, Aeq, beq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this, we get the processed A, b, Aeq and beq and we keep them in distinct variables correspodingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_proc = proc[0]\n",
    "b_proc = proc[1]\n",
    "Aeq_proc = proc[2]\n",
    "beq_proc = proc[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you the ```pre_process``` step had already run, you may load its output using the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_proc = np.load('/home/haris/Documents/GitHub/volesti_fork/volestipy/tests/A_preprocessed.npy')\n",
    "b_proc = np.load('/home/haris/Documents/GitHub/volesti_fork/volestipy/tests/b_preprocessed.npy')\n",
    "Aeq_proc = np.load('/home/haris/Documents/GitHub/volesti_fork/volestipy/tests/Aeq_preprocessed.npy')\n",
    "beq_proc = np.load('/home/haris/Documents/GitHub/volesti_fork/volestipy/tests/beq_preprocessed.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Aeq_proc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full dimensional (not always required step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are able to use the pre processed polytope to get the full dimensional polytope that derives from our initial one. To this end we first build an object for the ```low_dim_HPolytope``` class for the pre-processed polytope. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_hp = low_dim_HPolytope(A_proc, b_proc, Aeq_proc, beq_proc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we run the ```full_dimensiolal_polytope``` function of ```volestipy``` to get it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_fd_hp = low_hp.full_dimensiolal_polytope()\n",
    "\n",
    "A_fd = get_fd_hp[0].A\n",
    "b_fd = get_fd_hp[0].b\n",
    "N = get_fd_hp[1]\n",
    "N_shift = get_fd_hp[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the full dimensional polytope, we are able to get the max ball of that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ball_center_point, max_ball_radius = get_max_ball(A_fd, b_fd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use this max ball for rounding the full dimensional polytope. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rounding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the A and b of the full dimensional polytope, we build a new HPolytope object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = HPolytope(A_fd, b_fd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we use the max ball to round it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounding_output_max_ellipsoid = hp.rounding_svd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now get the features or the rounded polytope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_A = rounding_output_max_ellipsoid[0]\n",
    "rounded_b = rounding_output_max_ellipsoid[1]\n",
    "rounded_T = rounding_output_max_ellipsoid[2]\n",
    "rounded_shift = rounding_output_max_ellipsoid[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And use the to get the max ball of this full dimensional, rounded polytope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_center_point, rounded_radius = get_max_ball(rounded_A, rounded_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_center_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_radius"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we build the full dimenionsal rounded polytope. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_polytope = HPolytope(rounded_A, rounded_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep the dimension of the rounded polytope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = rounded_polytope.dimensions\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And calculate the value of the L parameter for the sampling function according the following formula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_value = 4 * d * rounded_radius"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And using the latter max ball, we sample on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = rounded_polytope.generate_samples(walk_len = 5, \n",
    "                                            number_of_points = 10000, \n",
    "                                            number_of_points_to_burn = 50, \n",
    "                                            radius = rounded_radius, \n",
    "                                            inner_point = rounded_center_point,\n",
    "                                            L = L_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And these are the points sampled: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, these samples \"live\" in the world of the rounded, full dimensional polytope. Thus, we need to map them back in our initial polyopte. To do that we run one last ```volestipy``` function, using the features returned from the ```rounding``` and the ```full_dimensional``` functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_samples = map_samples_on_initial_polytope(samples, rounded_T, rounded_shift, N, N_shift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look on our final points and their dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_samples.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis, plots etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the ```matplotlib``` library to plot our random samples. First, we download it to our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can import it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We mentioned that we are insterested in the HEX1 reaction that we have already kept as a variable and that we saw that its index is 218 on the reactions list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep all the fluxes' values from the points sampled for this reactions in a variable. And we print its shape to be sure that we have got this right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluxes = mapped_samples[218,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can get the minimum and the maximum value of ETOHt2r flux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxElement = np.amax(fluxes)\n",
    "minElement = np.amin(fluxes)\n",
    "maxElement, minElement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we may plot our samples! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([x for x in range(samples.shape[0])])\n",
    "plt.plot(x, fluxes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And also as an histogram!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.hist(fluxes, bins='auto', histtype='bar', rwidth=0.7)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you need to work with ```.mat``` files you need to implement some further steps that are not in the interest of this tutorial. \n",
    "\n",
    "To read a ```.mat``` file you need some extra Python libraries, as it is quite a challenging task. If you are more interested in that, you can read this article [here](https://scipy-cookbook.readthedocs.io/items/Reading_mat_files.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the h5py library in case you are working with .mat files of 7.3 release of Matlab and after \n",
    "#!sudo -H -S pip install h5py < /home/haris/Desktop/running/metabolic_network_pipeline_volestipy/\\\n",
    "#my_project_virtual_env/error.txt\n",
    "#print(\"*** The h5py library has now been installed *** \\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the tables library to read .mat files\n",
    "#!sudo -H -S pip3 install tables < /home/haris/Desktop/running/metabolic_network_pipeline_volestipy\\\n",
    "#/my_project_virtual_env/error.txt\n",
    "#print(\"*** The tables library has now been installed *** \\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Matlab up to 7.1 = mat files created with Matlab up to version 7.1 can be read using the mio module part of scipy.io.\n",
    "#from scipy.io import loadmat \n",
    "#\n",
    "## Beginning at release 7.3 of Matlab, mat files are actually saved using the HDF5 format by default (except if you use the -vX flag at save time, see in Matlab). These files can be read in Python using, for instance, the PyTables or h5py package\n",
    "#import tables \n",
    "#import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the ggplot - oriented Python library\n",
    "#!sudo -H -S pip3 install -t \"/home/haris/anaconda3/lib/python3.7/site-packages/\" --upgrade pandas plotnine \\\n",
    "#< /home/haris/Desktop/running/metabolic_network_pipeline_volestipy/my_project_virtual_env/error.txt\n",
    "#print(\"*** The ggplot for Python library has now been installed *** \\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mat_file_with_loadmat = loadmat('/home/haris/Downloads/e_coli_core.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this one is in case of ```.mat``` files created by releases of Matlab later after the 7.3\n",
    "This command will not run in any other case.\n",
    "For this demo we will use the ```loadmat``` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mat_file_with_tables = h5py.File('/home/haris/Downloads/e_coli_core.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can see your metabolic network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mat_file_with_loadmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_from_mat = mat_file_with_loadmat\n",
    "#print(\"the data type of the variable with the network as it was read is: \" + str(type(data_from_mat)))\n",
    "\n",
    "#s_matrix = data_from_mat.keys()\n",
    "#print(\"\\nthe keys of this dictionaries are: \")\n",
    "#print(s_matrix)\n",
    "\n",
    "#e_coli_np_void = data_from_mat['e_coli_core'][0][0]\n",
    "#print(\"\\nHowever, if we keep the key:value pair of this dictionary, called 'e_coli_core' where the necessary \\\n",
    "#information is located, we can see that its type is: \" + str(type(e_coli_np_void)) + \"\\n\\n\")\n",
    "\n",
    "#print(\"number of dimensions of the np.void data type equals to:\" + str(e_coli_np_void.ndim) + \"\\n\")\n",
    "\n",
    "#print(type(e_coli_np_void))\n",
    "#print(len(e_coli_np_void))\n",
    "\n",
    "\n",
    "\n",
    "## metabolites\n",
    "#print(type(e_coli_np_void[0]))\n",
    "#print(e_coli_np_void[0].shape)\n",
    "\n",
    "#print(type(e_coli_np_void[0][0]))\n",
    "#print(e_coli_np_void[0][0].shape)\n",
    "\n",
    "#print(e_coli_np_void[0][:3,])\n",
    "#metabolites = [item[0][0] for item in e_coli_np_void[0]]\n",
    "#print(metabolites)\n",
    "\n",
    "## genes\n",
    "#print(type(e_coli_np_void[4]))\n",
    "#print(e_coli_np_void[4].shape)\n",
    "#print(e_coli_np_void[4][:3,])\n",
    "\n",
    "## reactions\n",
    "#print(type(e_coli_np_void[7]))\n",
    "#print(e_coli_np_void[7].shape)\n",
    "#print(e_coli_np_void[7][:3,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for key,value in data_from_mat.items():\n",
    "#    print(str(key) + \"\\t\" + str(value))\n",
    "#    print(\"\\n\\n\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounding_output_max_ellipsoid = hp.rounding(rounding_method = \"max_ellipsoid\", \n",
    "                                            inner_point = max_ball_center_point, \n",
    "                                            radius = max_ball_radius)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
